name: KinD e2e tests

on:
  pull_request:
    branches: [ 'main', 'release-*' ]

defaults:
  run:
    shell: bash
    working-directory: ./src/knative.dev/serving

jobs:

  e2e-tests:
    name: e2e tests
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false # Keep running if one leg fails.
      matrix:
        k8s-version:
        - v1.19.11
        - v1.20.7
        - v1.21.1

        test-suite:
        - ./test/e2e

        # Map between K8s and KinD versions.
        # This is attempting to make it a bit clearer what's being tested.
        # See: https://github.com/kubernetes-sigs/kind/releases
        include:
        - k8s-version: v1.19.11
          kind-version: v0.11.1
          kind-image-sha: sha256:07db187ae84b4b7de440a73886f008cf903fcf5764ba8106a9fd5243d6f32729
          cluster-suffix: c${{ github.run_id }}.local
        - k8s-version: v1.20.7
          kind-version: v0.11.1
          kind-image-sha: sha256:cbeaf907fc78ac97ce7b625e4bf0de16e3ea725daf6b04f930bd14c67c671ff9
          cluster-suffix: c${{ github.run_id }}.local
        - k8s-version: v1.21.1
          kind-version: v0.11.1
          kind-image-sha: sha256:69860bda5563ac81e3c0057d654b5253219618a22ec3a346306239bba8cfa1a6
          cluster-suffix: c${{ github.run_id }}.local

    env:
      GOPATH: ${{ github.workspace }}
      GO111MODULE: off
      GOFLAGS: -tags=nostackdriver
      # https://github.com/google/go-containerregistry/pull/125 allows insecure registry for
      # '*.local' hostnames. This works both for `ko` and our own tag-to-digest resolution logic,
      # thus allowing us to test without bypassing tag-to-digest resolution.
      REGISTRY_NAME: registry.local
      REGISTRY_PORT: 5000
      KO_DOCKER_REPO: registry.local:5000/knative

    steps:
    - name: Set up Go 1.16.x
      uses: actions/setup-go@v2
      with:
        go-version: 1.16.x

    - name: Install Dependencies
      working-directory: ./
      run: |
        echo '::group:: install ko'
        curl -L https://github.com/google/ko/releases/download/v0.6.0/ko_0.6.0_Linux_x86_64.tar.gz | tar xzf - ko
        chmod +x ./ko
        sudo mv ko /usr/local/bin
        echo '::endgroup::'

    - name: Check out code onto GOPATH
      uses: actions/checkout@v2
      with:
        path: ./src/knative.dev/serving

    - name: Install KinD
      run: |
        set -x

        # Disable swap otherwise memory enforcement doesn't work
        # See: https://kubernetes.slack.com/archives/CEKK1KTN2/p1600009955324200
        sudo swapoff -a
        sudo rm -f /swapfile

        curl -Lo ./kind https://github.com/kubernetes-sigs/kind/releases/download/${{ matrix.kind-version }}/kind-$(uname)-amd64
        chmod +x ./kind
        sudo mv kind /usr/local/bin

    - name: Configure KinD Cluster
      working-directory: ./src/knative.dev/serving
      run: |
        set -x

        # KinD configuration.
        cat > kind.yaml <<EOF
        apiVersion: kind.x-k8s.io/v1alpha4
        kind: Cluster

        # Configure registry for KinD.
        containerdConfigPatches:
        - |-
          [plugins."io.containerd.grpc.v1.cri".registry.mirrors."$REGISTRY_NAME:$REGISTRY_PORT"]
            endpoint = ["http://$REGISTRY_NAME:$REGISTRY_PORT"]

        # This is needed in order to support projected volumes with service account tokens.
        # See: https://kubernetes.slack.com/archives/CEKK1KTN2/p1600268272383600
        kubeadmConfigPatches:
          - |
            apiVersion: kubeadm.k8s.io/v1beta2
            kind: ClusterConfiguration
            metadata:
              name: config
            apiServer:
              extraArgs:
                "service-account-issuer": "kubernetes.default.svc"
                "service-account-signing-key-file": "/etc/kubernetes/pki/sa.key"
            networking:
              dnsDomain: "${{ matrix.cluster-suffix }}"

        nodes:
        - role: control-plane
          image: kindest/node:${{ matrix.k8s-version }}@${{ matrix.kind-image-sha }}
        - role: worker
          image: kindest/node:${{ matrix.k8s-version }}@${{ matrix.kind-image-sha }}
        EOF

    - name: Create KinD Cluster
      working-directory: ./src/knative.dev/serving
      run: |
        set -x

        kind create cluster --config kind.yaml

    - name: Setup local registry
      run: |
        # Run a registry.
        docker run -d --restart=always \
          -p $REGISTRY_PORT:$REGISTRY_PORT --name $REGISTRY_NAME registry:2

        # Connect the registry to the KinD network.
        docker network connect "kind" $REGISTRY_NAME

        # Make the $REGISTRY_NAME -> 127.0.0.1, to tell `ko` to publish to
        # local reigstry, even when pushing $REGISTRY_NAME:$REGISTRY_PORT/some/image
        sudo echo "127.0.0.1 $REGISTRY_NAME" | sudo tee -a /etc/hosts

    - name: Install Knative Serving
      env:
        GO111MODULE: on
        GOFLAGS: -mod=vendor
      run: |
        set -o pipefail

        kubectl apply --filename https://storage.googleapis.com/knative-nightly/serving/latest/serving-crds.yaml
        kubectl wait --for=condition=Established --all crd
        kubectl apply --filename https://storage.googleapis.com/knative-nightly/serving/latest/serving-core.yaml

        # Have Serving use the kingress option.
        kubectl patch configmap/config-network \
          --namespace knative-serving \
          --type merge \
          --patch '{"data":{"ingress.class":"istio.ingress.networking.knative.dev"}}'

    - name: Install kingress provider (Istio)
      run: |
        set -o pipefail

        curl -sL https://istio.io/downloadIstioctl | sh -
        $HOME/.istioctl/bin/istioctl install -y

        echo "GATEWAY_NAMESPACE_OVERRIDE=istio-system" >> $GITHUB_ENV

    - name: Install metadata-webhook
      env:
        GO111MODULE: on
        GOFLAGS: -mod=vendor
      run: |
        ko apply --platform=linux/amd64 -PRf config/


    - name: Wait for Serving and webhook to be up
      run: |
        kubectl wait pod --for=condition=Ready -n knative-serving -l '!job-name'
        kubectl wait pod --for=condition=Ready -n serving-tests -l '!job-name'
        kubectl wait pod --for=condition=Ready -n "${GATEWAY_NAMESPACE_OVERRIDE}" -l '!job-name'

    - name: Run simple test
      run: |
        cat <<EOF | kubectl apply -f -
        apiVersion: serving.knative.dev/v1
        kind: Service
        metadata:
          name: hello
          namespace: serving-tests
        spec:
          template:
            metadata:
              name: hello-1
            spec:
              containers:
              - image: docker.io/openshift/hello-openshift
                name: container
        EOF
        kubectl get -n serving-tests ksvc hello -o=jsonpath='{.spec.template.metadata.annotations}' \
                    | grep '"sidecar.istio.io/inject":"true","sidecar.istio.io/rewriteAppHTTPProbers":"true"' || exit 1
        kubectl get -n serving-tests ksvc hello -o=jsonpath='{.metadata.annotations}' \
                    | grep '"serving.knative.openshift.io/enablePassthrough":"true"' || exit 1

        cat <<EOF | kubectl apply -f -
        apiVersion: serving.knative.dev/v1
        kind: Configuration
        metadata:
          name: configuration-example
          namespace: serving-tests
        spec:
          template:
            spec:
              containers:
              - image: docker.io/openshift/hello-openshift
        EOF

        cat <<EOF | kubectl apply -f -
        apiVersion: serving.knative.dev/v1
        kind: Route
        metadata:
          name: route-example
          namespace: serving-tests
        spec:
          traffic:
          - configurationName: configuration-example
            percent: 100
        EOF

        cat <<EOF | kubectl apply -f -
        apiVersion: serving.knative.dev/v1alpha1
        kind: DomainMapping
        metadata:
          name: mydomain.example.com
          namespace: serving-tests
        spec:
          ref:
            name: hello
            kind: Service
            apiVersion: serving.knative.dev/v1
        EOF

        kubectl get -n serving-tests configuration configuration-example -o=jsonpath='{.spec.template.metadata.annotations}' \
                    | grep '"sidecar.istio.io/inject":"true","sidecar.istio.io/rewriteAppHTTPProbers":"true"' || exit 1
        kubectl get -n serving-tests route route-example -o=jsonpath='{.metadata.annotations}' \
                    | grep '"serving.knative.openshift.io/enablePassthrough":"true"' || exit 1

        kubectl get -n serving-tests domainmapping mydomain.example.com -o=jsonpath='{.metadata.annotations}' \
                    | grep '"serving.knative.openshift.io/enablePassthrough":"true"' || exit 1
 

#    - name: Run e2e Tests
#      run: |
#        set -x
#
#        # Exclude the control-plane node, which doesn't seem to expose the nodeport service.
#        IPS=( $(kubectl get nodes -lkubernetes.io/hostname!=kind-control-plane -ojsonpath='{.items[*].status.addresses[?(@.type=="InternalIP")].address}') )
#
#        # Run the tests tagged as e2e on the KinD cluster.
#        go test -race -count=1 -timeout=20m -tags=e2e ${{ matrix.test-suite }} \
#           --ingressendpoint="${IPS[0]}" \
#           ${{ matrix.test-flags }}
